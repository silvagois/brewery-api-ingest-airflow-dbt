# ğŸº Brewery Plataforma de Dados (DuckDB + dbt + Airflow)

## ğŸ“Œ Overview

Esse projeto implementa uma plataforma de dados moderna localmente usando  **DuckDB**( Simulando um modern Data Warehouse como Bigquery, Snowflake, Redshift ou Databricks), **dbt**, and **Apache Airflow**, seguindo a arquitetura de dados **Medallion Architecture (Bronze / Silver / Gold)** Decidi alterar um pouco a arquitetura Medallion tradicional inserindo uma landing zone com os dados brutos e na bronze os dados sem alteraÃ§Ã£o porÃ©m em formato parquet particionados.

Este pipeline de dados extrai dados via Python requests na **Open Brewery DB API**, armazena na **Landing Zone**  em seu formato bruto raw, o Apache Airflow trigga seu schedule diÃ¡rio coletando dados da landing e armazenando na layer **Bronze** particionado por data YYYY-MM-DD em formato parquet, onde Ã© feito limpeza e transformaÃ§Ã£o na **Silver** layer e agregado na **Gold** um pipeline simples que pode ser usando em diferentes cenÃ¡rios, clouds usando das melhores praticas de Data Quality, Data Governance, Data Contracts, Monitoring, Observability, CI no desenvolvimento deste projeto. Como esse pipeline foi feito local usando Docker os dados estÃ£o armazenados nos volumes porÃ©m inseridos no banco de dados duckdb simulando um Datalake que seja ou num S3/Databricks Lakehouse, ou em Dataset no bigquery por exemplo, a ideia Ã© mostrar os conceitos utilizados e os mesmos podem ser dsenvolvidos em diferentes ambientes 

---

## ğŸ—ï¸ Arquitetura

```
API
â†“
Landing (JSON)
â†“
Bronze (Parquet / External Tables)
â†“
Silver (Incremental / Cleaned)
â†“
Gold (Aggregated / Analytics)
```

#### Arquitetura do Projeto

<img src="docs/architecture.png" alt="DescriÃ§Ã£o" width="500" height="auto">


- **DuckDB**: Engine storage analitica
- **dbt**: TransformaÃ§Ãµes, testing, contrato de dados
- **Airflow**: OrquestraÃ§Ã£o
- **Docker**: ReproduÃ§Ã£o Local
- **GitHub Actions**: CI com dbt tests

---

## ğŸ“‚ Project Structure

```
duckdb-dbt-airflow/
â”‚
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ landing/ # Raw JSON files partitioned by ingestion date
â”‚ â”œâ”€â”€ bronze/ # External Parquet tables (dbt external models)
â”‚ â”œâ”€â”€ silver/ # Cleaned and incremental tables
â”‚ â”œâ”€â”€ gold/ # Aggregated analytical tables
â”‚ â””â”€â”€ duckdb/
â”‚ â””â”€â”€ brewery.duckdb
â”‚
â”œâ”€â”€ dbt/
â”‚ â”œâ”€â”€ dbt_project.yml
â”‚ â”œâ”€â”€ profiles.yml
â”‚ â””â”€â”€ models/
â”‚ â”œâ”€â”€ bronze/
â”‚ â”œâ”€â”€ silver/
â”‚ â””â”€â”€ gold/
â”‚
â”œâ”€â”€ dags/
â”‚ â””â”€â”€ brewery_pipeline_dag.py
â”‚
â”œâ”€â”€ src/
â”‚ â””â”€â”€ ingestion/
â”‚ â””â”€â”€ ingest_landing.py
â”‚
â”œâ”€â”€ tests/
â”‚ â””â”€â”€ breweries.yml
â”‚
â”œâ”€â”€ .github/
â”‚ â””â”€â”€ workflows/
â”‚ â””â”€â”€ dbt-ci.yml
â”‚
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

```


---

## âš™ï¸ Como executar localmente

### 1ï¸âƒ£ Iniciando a Plataforma (Airflow + dbt + DuckDB)

```bash
docker-compose -p airflow up --build

```

Uma vez que o container esta rodando, acesse:

Airflow UI: http://localhost:8080

- User: airflow

- Password: airflow

## 2ï¸âƒ£ Trigando o pipeline

**No Airflow UI:**

- Procure a DAG `brewery_data_pipeline`

- Acione ela manualmente ou deixe executar via scheduler

**O pipeline irÃ¡ fazer:**

- Ingerir dados da Open Brewery DB API

- Armazenar dados brutos na Ã¡rea de destino (JSON)

- Transformar dados usando dbt (Bronze â†’ Silver â†’ Gold)

- Executar testes de qualidade de dados

# Qualidade de Dados com dbt: Testes e Data Contracts

Este projeto utiliza **dbt** como camada central de qualidade de dados, aplicando **testes automÃ¡ticos**, **data contracts** e integraÃ§Ã£o com **Airflow** e **CI** para garantir confiabilidade pontaâ€‘aâ€‘ponta no pipeline.

---

## ğŸ¯ Objetivos desta etapa

* Garantir **qualidade e consistÃªncia** dos dados transformados
* Detectar falhas **antes** de dados chegarem Ã  camada Gold
* Formalizar expectativas de schema via **Data Contracts**
* Automatizar validaÃ§Ãµes via **Airflow** e **CI/CD**

---

## ğŸ§± Onde a qualidade entra na arquitetura

```
Landing â†’ Bronze â†’ Silver â†’ Gold
              â†‘        â†‘
         Tests bÃ¡sicos  Tests + Contracts
```

* **Bronze**: validaÃ§Ãµes mÃ­nimas (existÃªncia de arquivo, schema flexÃ­vel)
* **Silver**: limpeza, deduplicaÃ§Ã£o, **contracts + testes**
* **Gold**: mÃ©tricas confiÃ¡veis, prontas para consumo

---

## âœ… Testes no dbt

Os testes sÃ£o definidos em arquivos `schema.yml` e executados com:

```bash
dbt test
```

### Exemplos de testes utilizados

```yaml
models:
  - name: breweries_silver
    columns:
      - name: brewery_type
        tests:
          - not_null
```

Tipos de testes comuns:

* `not_null`
* `unique`
* `accepted_values`
* `relationships`

Esses testes sÃ£o **automÃ¡ticos** e falham o pipeline caso alguma regra seja violada.

---

## ğŸ“œ Data Contracts (dbt)

O projeto utiliza **Data Contracts** para garantir que o schema dos modelos Silver seja **estritamente controlado**.

### Exemplo de contract

```yaml
models:
  - name: breweries_silver
    config:
      contract:
        enforced: true
    columns:
      - name: brewery_id
        data_type: varchar
      - name: brewery_type
        data_type: varchar
```

### O que o contract garante?

* Tipos de dados corretos
* Colunas obrigatÃ³rias
* Quebras explÃ­citas em caso de mudanÃ§as inesperadas

Se o SQL gerar um tipo incompatÃ­vel, o `dbt run` **falha imediatamente**.

---

## â±ï¸ Quando os testes e contracts sÃ£o executados?

### 1ï¸âƒ£ Durante o `dbt run`

* Contracts sÃ£o validados **no momento da criaÃ§Ã£o do modelo**
* Falha rÃ¡pida (failâ€‘fast)

### 2ï¸âƒ£ Durante o `dbt test`

* Testes de qualidade sÃ£o executados apÃ³s a criaÃ§Ã£o dos modelos
* Qualquer falha interrompe o pipeline

---

## ğŸŒ€ IntegraÃ§Ã£o com Airflow

A DAG possui uma task dedicada para testes:

```python
dbt_test = BashOperator(
    task_id="dbt_test",
    bash_command="""
      cd /opt/airflow/dbt && \
      dbt test \
        --project-dir /opt/airflow/dbt \
        --profiles-dir /opt/airflow/dbt
    """
)
```

Fluxo simplificado:

```
ingest â†’ dbt_bronze â†’ dbt_silver â†’ dbt_gold â†’ dbt_test
```

---

Perfeito â€” segue **todo o conteÃºdo jÃ¡ no formato final de README.md**, sem blocos extras, pronto para **copiar e colar diretamente** no seu `README.md` geral.

---

## ğŸ” CI â€“ Continuous Integration com dbt

Este repositÃ³rio possui um pipeline de **CI (Continuous Integration)** utilizando **GitHub Actions**, responsÃ¡vel por garantir **qualidade, consistÃªncia e governanÃ§a** dos dados antes de qualquer alteraÃ§Ã£o ser integrada ao branch `main`.

O CI valida automaticamente **modelos, testes e contratos de dados do dbt** a cada `push` ou `pull request`.

---

## ğŸ¯ Objetivos do CI

O pipeline de CI garante que:

* Todos os modelos dbt **compilam e executam corretamente**
* **Testes de dados** (not null, unique, accepted values, etc.) sÃ£o respeitados
* **Contratos de dados (dbt contracts)** sÃ£o validados
* Nenhuma alteraÃ§Ã£o quebre a arquitetura **Bronze / Silver / Gold**
* Erros sÃ£o detectados **antes** de chegar Ã  produÃ§Ã£o

---

## âš™ï¸ Quando o CI Ã© executado

O CI roda automaticamente em:

* Todo **Pull Request**
* Todo **push para o branch `main`**

ConfiguraÃ§Ã£o de trigger:

```yaml
on:
  pull_request:
  push:
    branches: [ main ]
```

---

## ğŸ§± Etapas do Pipeline

### 1ï¸âƒ£ Checkout do cÃ³digo

Clona o repositÃ³rio para o runner do GitHub Actions.

```yaml
- uses: actions/checkout@v4
```

---

### 2ï¸âƒ£ Setup do ambiente Python

Define a versÃ£o do Python usada no CI, garantindo consistÃªncia com o ambiente local.

```yaml
- name: Set up Python
  uses: actions/setup-python@v5
  with:
    python-version: "3.11"
```

---

### 3ï¸âƒ£ InstalaÃ§Ã£o das dependÃªncias

Instala todas as dependÃªncias necessÃ¡rias para execuÃ§Ã£o do dbt.

```yaml
- name: Install dependencies
  run: |
    pip install -r requirements.txt
```

Inclui:

* `dbt-core`
* `dbt-duckdb`
* bibliotecas auxiliares

---

### 4ï¸âƒ£ Download de pacotes dbt

Baixa pacotes definidos no `packages.yml` (ex: `dbt-utils`).

```yaml
- name: Run dbt deps
  run: |
    cd dbt
    dbt deps
```

---

### 5ï¸âƒ£ Build completo com dbt

Executa modelos, testes e contratos em uma Ãºnica etapa.

```yaml
- name: Run dbt build
  run: |
    cd dbt
    dbt build --fail-fast
```

O comando `dbt build` executa:

* `dbt run` â†’ cria os modelos
* `dbt test` â†’ executa testes e contratos
* Seeds e snapshots (se existirem)

O parÃ¢metro `--fail-fast` interrompe o pipeline ao primeiro erro, reduzindo o tempo de feedback.

---

## ğŸ§ª Testes de Dados

Os testes sÃ£o definidos nos arquivos `schema.yml` e executados automaticamente durante o CI.

Exemplo de testes:

```yaml
models:
  - name: breweries_silver
    columns:
      - name: brewery_id
        tests:
          - not_null
          - unique
```

Tipos comuns de testes:

* `not_null`
* `unique`
* `accepted_values`
* testes customizados

Qualquer violaÃ§Ã£o faz o pipeline falhar.

---

## ğŸ“œ Contratos de Dados (dbt Contracts)

Os contratos garantem que os modelos entregam **estrutura estÃ¡vel, tipada e versionada**.

Exemplo de contrato:

```yaml
models:
  - name: breweries_silver
    config:
      contract:
        enforced: true
    columns:
      - name: brewery_id
        data_type: varchar
      - name: brewery_type
        data_type: varchar
```

O CI falha se:

* Uma coluna esperada nÃ£o existir
* O tipo de dado estiver incorreto
* A estrutura do modelo mudar sem controle

---

## ğŸš« O que faz o CI falhar

O pipeline falha automaticamente se ocorrer:

* Erro de SQL
* Modelo dbt quebrado
* Teste de dados violado
* Contrato de dados nÃ£o respeitado
* Erro de dependÃªncia ou compilaÃ§Ã£o

---

## âœ… BenefÃ­cios do CI

* GovernanÃ§a de dados desde o cÃ³digo
* PrevenÃ§Ã£o de regressÃµes
* ConfianÃ§a para evoluir modelos
* Base sÃ³lida para deploy em cloud
* Alinhamento com **Data Platforms modernas**

---

## ğŸš¨ O que acontece em caso de falha?

* âŒ Teste falhou â†’ `dbt test` retorna exit code â‰  0
* âŒ Contract violado â†’ `dbt run` falha
* âŒ Airflow marca a task como **FAILED**
* âŒ Pipeline nÃ£o avanÃ§a para Gold

---

## ğŸ§  Boas prÃ¡ticas adotadas

* Testes comeÃ§am no Silver (dados jÃ¡ tratados)
* Contracts apenas onde hÃ¡ consumidores crÃ­ticos
* Tasks separadas para `run` e `test`
* Mesmo comando no Airflow e CI

---

## ğŸ Resultado

Com essa abordagem, o pipeline garante:

âœ” Dados confiÃ¡veis
âœ” Quebras explÃ­citas e controladas
âœ” Observabilidade
âœ” Pronto para escala e produÃ§Ã£o

---

> "Qualidade de dados nÃ£o Ã© uma etapa final, Ã© parte do design do pipeline."
> â€” Data Engineering mindset

Perfeito â€” abaixo estÃ¡ a **documentaÃ§Ã£o completa de ğŸ” Observability & Reliability**, jÃ¡ **100% no formato aceito por README.md**, pronta para copiar e colar no seu repositÃ³rio.

---

## ğŸ” Observability & Reliability

Este projeto foi desenhado com foco em **observabilidade, confiabilidade e rastreabilidade de dados**, seguindo boas prÃ¡ticas de **Data Platforms modernas**.

A observabilidade permite responder rapidamente Ã s perguntas:

* O pipeline rodou?
* Onde falhou?
* Os dados estÃ£o completos, corretos e atualizados?
* Qual camada foi impactada?

---

## ğŸ§± Camadas de Observabilidade

A observabilidade estÃ¡ distribuÃ­da em **quatro nÃ­veis principais**:

1. **IngestÃ£o (Landing)**
2. **TransformaÃ§Ãµes (dbt â€“ Bronze / Silver / Gold)**
3. **OrquestraÃ§Ã£o (Airflow)**
4. **CI / Qualidade de Dados**

---

## ğŸ“¥ Observability na IngestÃ£o (Landing)

Durante a ingestÃ£o da API:

* Cada execuÃ§Ã£o cria um **diretÃ³rio particionado por data**
* Logs explÃ­citos informam:

  * Caminho do arquivo gerado
  * Quantidade de registros ingeridos
* Falhas de API interrompem o pipeline imediatamente

Exemplo de log:

```text
[OK] Landing file written to /opt/airflow/data/landing/breweries/2026-02-01/list_breweries.json
[OK] Records ingested: 50
```

BenefÃ­cios:

* Rastreamento por data (`execution_date`)
* Reprocessamento simples por partiÃ§Ã£o
* Debug rÃ¡pido de falhas upstream

---

## ğŸ§ª Observability nas TransformaÃ§Ãµes (dbt)

### ğŸ“Š MÃ©tricas automÃ¡ticas

Cada modelo dbt gera artefatos de observabilidade:

* `run_results.json`
* `manifest.json`
* `catalog.json`

Esses artefatos permitem:

* Ver quais modelos rodaram
* Identificar tempo de execuÃ§Ã£o
* Diagnosticar falhas de dependÃªncia

---

### ğŸ§± Contratos de Dados

Os **dbt contracts** garantem estabilidade estrutural dos dados.

Se a estrutura esperada mudar, o pipeline falha imediatamente.

Exemplo:

```yaml
config:
  contract:
    enforced: true
```

Isso evita:

* Quebras silenciosas
* MudanÃ§as inesperadas para consumidores downstream
* Erros em dashboards e APIs

---

### ğŸ§ª Testes de Qualidade

Testes dbt garantem:

* NÃ£o nulidade (`not_null`)
* Unicidade (`unique`)
* Valores vÃ¡lidos (`accepted_values`)
* Integridade referencial (quando aplicÃ¡vel)

Todos os testes sÃ£o executados:

* No Airflow (`dbt test`)
* No CI (GitHub Actions)

---

## ğŸ” Incrementalidade & Confiabilidade

Na camada **Silver**, os modelos:

* MantÃªm apenas o **registro mais recente por chave**
* Evitam duplicaÃ§Ãµes
* Garantem idempotÃªncia

Exemplo de lÃ³gica:

```sql
ROW_NUMBER() OVER (
  PARTITION BY brewery_id
  ORDER BY ingestion_date DESC
)
```

BenefÃ­cios:

* Reprocessamentos seguros
* CorreÃ§Ã£o de dados histÃ³ricos
* Alta confiabilidade operacional

---

## â±ï¸ Observability no Airflow

O Airflow fornece:

* UI visual com status por task
* Logs detalhados por execuÃ§Ã£o
* Retry automÃ¡tico em falhas transitÃ³rias
* Alertas visuais de erro

ConfiguraÃ§Ãµes relevantes:

```python
default_args = {
    "retries": 2,
    "retry_delay": timedelta(minutes=1),
}
```

Cada etapa do pipeline Ã© isolada:

* IngestÃ£o
* Bronze
* Silver
* Gold
* Testes

Falhas sÃ£o **localizadas e rastreÃ¡veis**.

---

## ğŸš¦ Fail Fast & Blast Radius Control

O pipeline segue o princÃ­pio de **fail fast**:

* Qualquer erro interrompe a execuÃ§Ã£o
* Nenhuma camada downstream roda com dados invÃ¡lidos
* O impacto (blast radius) Ã© controlado

Exemplo:

* Falha na ingestÃ£o â†’ dbt nÃ£o executa
* Falha no Bronze â†’ Silver e Gold nÃ£o executam

---

## ğŸ” Confiabilidade no CI

O CI atua como **Ãºltima linha de defesa** antes do merge:

* Nenhuma mudanÃ§a entra sem:

  * Modelos vÃ¡lidos
  * Testes aprovados
  * Contratos respeitados

Se o CI falhar:

* O PR Ã© bloqueado
* A alteraÃ§Ã£o nÃ£o chega Ã  produÃ§Ã£o

---

## ğŸ“ˆ Indicadores de Confiabilidade

Este projeto permite monitorar:

* Sucesso/falha por execuÃ§Ã£o
* Volume de registros por partiÃ§Ã£o
* Freshness dos dados
* Integridade estrutural dos modelos

Esses indicadores sÃ£o base para:

* SLAs de dados
* Alertas automatizados
* Monitoramento futuro (Great Expectations, OpenLineage, etc.)

---

## ğŸ› ï¸ PossÃ­veis EvoluÃ§Ãµes

Este projeto estÃ¡ pronto para evoluir para:

* Great Expectations
* dbt Freshness Checks
* OpenLineage / Marquez
* Data SLAs
* Alertas por Slack / Email
* Observabilidade centralizada (Datadog, Prometheus)
* Testes Unitarios

---

## ğŸ† VisÃ£o de Engenharia de Dados

> â€œA plataforma foi desenhada com observabilidade em todas as camadas: ingestÃ£o, transformaÃ§Ã£o, orquestraÃ§Ã£o e CI. Falhas sÃ£o detectadas cedo, isoladas e rastreÃ¡veis.â€

---


## ğŸ‘¨â€ğŸ’» Autor

Marcos Antonio de Gois Silva ( Data & Analytics - 2026)